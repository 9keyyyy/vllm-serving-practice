[project]
name = "vllm-serving-practice"
version = "0.1.0"
description = "LLM serving with vLLM batch processing"
readme = "README.md"
requires-python = ">=3.13"
dependencies = [
    "aiohttp>=3.13.2",
    "fastapi>=0.122.0",
    "httpx>=0.28.1",
    "langchain>=1.1.0",
    "langchain-openai>=1.1.0",
    "openai>=2.8.1",
    "prometheus-client>=0.23.1",
    "pydantic>=2.12.4",
    "pydantic-settings>=2.12.0",
    "python-dotenv>=1.2.1",
    "uvicorn>=0.38.0",
]

[dependency-groups]
dev = [
    "httpx>=0.28.1",
    "mypy>=1.18.2",
    "pytest>=9.0.1",
    "pytest-asyncio>=1.3.0",
    "ruff>=0.14.6",
]

[tool.ruff]
line-length = 88 
target-version = "py313"  

[tool.ruff.lint]
select = ["E", "F", "I"]  # pycodestyle, pyflakes, isort 규칙
ignore = []

[tool.mypy]
python_version = "3.13"
strict = false
warn_unused_configs = true
disallow_untyped_defs = true
disallow_any_unimported = false
warn_return_any = true